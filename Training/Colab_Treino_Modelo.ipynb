{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treinamento do Modelo: Curador.IA\n",
        "\n",
        "**Contexto:** Projeto da disciplina de Processamento Digital de Imagens (PDI) / Visão Computacional.\n",
        "**Objetivo:** Treinar uma Rede Neural Convolucional (CNN) capaz de classificar obras de arte de 5 mestres da pintura (Monet, Da Vinci, Picasso, Dalí, Van Gogh).\n",
        "\n",
        "### Pipeline deste Notebook:\n",
        "\n",
        "1.  **Transfer Learning:** Utilizamos a arquitetura **MobileNetV2** (pré-treinada no ImageNet) como extrator de características, adicionando camadas densas personalizadas para nossa classificação.\n",
        "2.  **Robustez (Data Augmentation):** O diferencial deste treino é a configuração agressiva do `ImageDataGenerator`. Simulamos variações de **brilho, rotação e perspectiva** para garantir que o modelo funcione ao capturar fotos de **telas de computador e impressões**, ignorando reflexos e distorções.\n",
        "3.  **Output:** O código gera o arquivo `modelo_artes.h5`, que será utilizado no frontend (Streamlit).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFlAQeAuX_XW",
        "outputId": "4b8f5780-72fb-439c-abe8-7340f89c92ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "A extrair o dataset (isto pode demorar alguns segundos)...\n",
            "✅ Sucesso! Ficheiros extraídos.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Configurar caminhos\n",
        "caminho_zip = '/content/drive/My Drive/dataset.zip'\n",
        "caminho_extracao = '/content/dataset_temp'\n",
        "\n",
        "# 3. Extrair\n",
        "if os.path.exists(caminho_zip):\n",
        "    print(\"Extraindo o dataset\")\n",
        "    with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(caminho_extracao)\n",
        "    print(\"Sucesso! pasta extraída.\")\n",
        "else:\n",
        "    print(\"ERRO: Não encontrei a pasta no seu Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg1TjS9cYWz-",
        "outputId": "661e16ff-044c-468f-e385-a6bee273595d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A carregar imagens de Treino...\n",
            "Found 923 images belonging to 5 classes.\n",
            "A carregar imagens de Validação...\n",
            "Found 232 images belonging to 5 classes.\n",
            "\n",
            "⚠️ ORDEM DAS CLASSES (Copie isto para o seu código final):\n",
            "['claude_monet', 'leonardo_da_vinci', 'pablo_picasso', 'salvador_dali', 'vincent_van_gogh']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Normalizar cores\n",
        "    rotation_range=20,          # Roda a imagem\n",
        "    width_shift_range=0.15,     # Move a imagem para os lados\n",
        "    height_shift_range=0.15,    # Move a imagem para cima/baixo\n",
        "    shear_range=0.15,           # Deforma a perspetiva\n",
        "    zoom_range=0.25,            # Simula zoom ou estar muito perto/longe\n",
        "    brightness_range=[0.5, 1.5],# Simula ecrãs muito brilhantes ou escuros\n",
        "    channel_shift_range=30.0,   # Altera ligeiramente as cores\n",
        "    horizontal_flip=True,       # Espelha a imagem\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Para a validação, usamos apenas a normalização\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Carregar as imagens das pastas\n",
        "print(\"A carregar imagens de Treino...\")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    f'{caminho_extracao}/dataset_projeto/train',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "print(\"A carregar imagens de Validação...\")\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    f'{caminho_extracao}/dataset_projeto/validation',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "print(list(train_generator.class_indices.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIdRlwzYrww",
        "outputId": "a7814c66-eefc-4e8a-8800-886904e49098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "A iniciar treino... (Isto vai demorar cerca de 5 a 10 minutos)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.4823 - loss: 1.3968 - val_accuracy: 0.6897 - val_loss: 0.7897\n",
            "Epoch 2/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 662ms/step - accuracy: 0.6714 - loss: 0.8712 - val_accuracy: 0.7241 - val_loss: 0.6888\n",
            "Epoch 3/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 692ms/step - accuracy: 0.7136 - loss: 0.7370 - val_accuracy: 0.7543 - val_loss: 0.6378\n",
            "Epoch 4/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 657ms/step - accuracy: 0.7524 - loss: 0.6372 - val_accuracy: 0.7112 - val_loss: 0.6945\n",
            "Epoch 5/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 703ms/step - accuracy: 0.7672 - loss: 0.6396 - val_accuracy: 0.7586 - val_loss: 0.5721\n",
            "Epoch 6/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 667ms/step - accuracy: 0.8086 - loss: 0.5388 - val_accuracy: 0.7672 - val_loss: 0.5739\n",
            "Epoch 7/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 702ms/step - accuracy: 0.7814 - loss: 0.5379 - val_accuracy: 0.7543 - val_loss: 0.6112\n",
            "Epoch 8/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 664ms/step - accuracy: 0.8462 - loss: 0.4237 - val_accuracy: 0.7759 - val_loss: 0.5621\n",
            "Epoch 9/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 704ms/step - accuracy: 0.8278 - loss: 0.4557 - val_accuracy: 0.7759 - val_loss: 0.5820\n",
            "Epoch 10/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 658ms/step - accuracy: 0.8407 - loss: 0.4152 - val_accuracy: 0.7759 - val_loss: 0.5680\n",
            "Epoch 11/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 697ms/step - accuracy: 0.8630 - loss: 0.3835 - val_accuracy: 0.7931 - val_loss: 0.5652\n",
            "Epoch 12/12\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 660ms/step - accuracy: 0.8493 - loss: 0.4251 - val_accuracy: 0.8233 - val_loss: 0.5243\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Carregar a base pré-treinada\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Congelamos a base\n",
        "base_model.trainable = False\n",
        "\n",
        "# 2. Adicionar as nossas camadas personalizadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x) \n",
        "x = Dropout(0.3)(x)                  # Ajuda a evitar decorar (overfitting)\n",
        "predictions = Dense(5, activation='softmax')(x) # 5 Classes de Artistas\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 3. Compilar\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Treinar\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=12,\n",
        "    validation_data=validation_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "zJHs4JuFY2pN",
        "outputId": "0bf856e1-e608-4191-806f-af74dfca087b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo modelo_artes_v2.h5 guardado!\n",
            "A iniciar download para o seu computador...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_76f828ed-b385-4480-98fc-5b91e1454ad2\", \"modelo_artes_v2.h5\", 13526112)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Salvar e baixar o arquivo\n",
        "from google.colab import files\n",
        "\n",
        "nome_modelo = 'modelo_artes.h5'\n",
        "model.save(nome_modelo)\n",
        "\n",
        "files.download(nome_modelo)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
